{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installs and imports\n",
        "\n",
        "!pip install --upgrade gym\n",
        "!pip install scikit-learn\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "!pip install shimmy\n",
        "!pip install d3rlpy"
      ],
      "metadata": {
        "id": "F_sozJMvSA2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from gym import spaces, Env\n",
        "import gc\n",
        "import zipfile\n",
        "import torch as th\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import threading\n",
        "from collections import defaultdict, Counter\n",
        "import torch\n",
        "import d3rlpy\n",
        "from d3rlpy.dataset import MDPDataset"
      ],
      "metadata": {
        "id": "TZx3hMgoSDwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing EdNet - Code to parse files into dataframe that we can process further"
      ],
      "metadata": {
        "id": "Td4x7KhIRS0c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_0vOHiJREUM"
      },
      "outputs": [],
      "source": [
        "\n",
        "extract_to = \"C:\\\\Columbia\\\\RL\\\\KT4\"\n",
        "\n",
        "# Get all CSV files in the directory\n",
        "all_files = [os.path.join(extract_to, f) for f in os.listdir(extract_to) if f.endswith(\".csv\")]\n",
        "len(all_files)\n",
        "\n",
        "# Load questions and payments data\n",
        "questions_file = 'C:\\\\Columbia\\\\RL\\\\EdNet-Contents\\\\contents\\\\questions.csv'\n",
        "payments_file = 'C:\\\\Columbia\\\\RL\\\\EdNet-Contents\\\\contents\\\\payments.csv'\n",
        "questions = pd.read_csv(questions_file)\n",
        "payments = pd.read_csv(payments_file)\n",
        "\n",
        "# Rename columns for consistency\n",
        "questions.rename(columns={'question_id': 'item_id'}, inplace=True)\n",
        "\n",
        "# Load all files into a single DataFrame\n",
        "print(\"Loading all files into a single DataFrame...\")\n",
        "all_data = []\n",
        "for file in tqdm.tqdm(all_files, desc=\"Reading Files\"):\n",
        "    student_df = pd.read_csv(file)\n",
        "    student_df['user_id'] = file.split('/')[-1].split('.')[0]  # Extract user_id from file name\n",
        "    if \"action_type\" in student_df.columns and \"pay\" not in student_df[\"action_type\"].values: # Filter students who don't have full access to the platform\n",
        "        continue\n",
        "    all_data.append(student_df)\n",
        "all_data = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "all_data[\"user_id\"] = all_data[\"user_id\"].apply(lambda x: x.split(\"\\\\\")[-1])\n",
        "all_data.columns\n",
        "\n",
        "# Join with questions.csv to determine correctness for questions\n",
        "print(\"Joining with questions.csv...\")\n",
        "all_data= pd.merge(all_data, questions, on='item_id', how='left')\n",
        "all_data.drop(\"Unnamed: 0\", axis = 1).to_csv(\"C:\\\\Columbia\\\\RL\\\\EdNet_KT4_PaidOnly.csv\", index = False)\n",
        "\n",
        "# Define organic sources\n",
        "organic_sources = ['diagnosis', 'sprint', 'review', 'in_review']\n",
        "maxTimeOnOneInteraction = 300000 # 5 minutes\n",
        "all_data['session_id'] = all_data.groupby('user_id')['timestamp'].diff().fillna(0).gt(maxTimeOnOneInteraction).cumsum()\n",
        "grouped = all_data.groupby(['user_id', 'session_id'])\n",
        "valid_sessions = grouped.filter(lambda x: x['source'].isin(organic_sources).any())\n",
        "\n",
        "# Calculate correctness for question rows\n",
        "print(\"Calculating correctness...\")\n",
        "valid_sessions['correct'] = valid_sessions.apply(\n",
        "    lambda x: 1 if (str(x['item_id']).startswith('q') and x['user_answer'] == x['correct_answer']) else 0,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Fill missing values\n",
        "valid_sessions.fillna({\n",
        "    'cursor_time': 0,\n",
        "    'correct': 0,\n",
        "    'action_type': 'unknown'\n",
        "}, inplace=True)\n",
        "print(len(valid_sessions[[\"user_id\", \"session_id\"]].drop_duplicates()))\n",
        "\n",
        "# Split into train and test sets\n",
        "# Get unique sessions\n",
        "unique_sessions = valid_sessions[['user_id', 'session_id']].drop_duplicates()\n",
        "# Perform train-test split on unique sessions\n",
        "# 70-15-15\n",
        "train_sessions, temp_sessions = train_test_split(\n",
        "    unique_sessions,\n",
        "    test_size=0.3,\n",
        "    random_state=101\n",
        ")\n",
        "\n",
        "val_sessions, test_sessions = train_test_split(\n",
        "        temp_sessions,\n",
        "        test_size=0.5,  # Adjust proportion for the second split\n",
        "        random_state=101\n",
        "    )\n",
        "\n",
        "# Merge back to get full train and test data\n",
        "train_data = valid_sessions.merge(train_sessions, on=['user_id', 'session_id'])\n",
        "val_data = valid_sessions.merge(val_sessions, on=['user_id', 'session_id'])\n",
        "test_data = valid_sessions.merge(test_sessions, on=['user_id', 'session_id'])\n",
        "\n",
        "dfWithRequiredCols = train_data[['user_id', 'session_id', 'timestamp', 'item_id', 'action_type', 'source', 'correct']]\n",
        "dfWithRequiredCols.to_csv(\"C:\\\\Columbia\\\\RL\\\\EdNet_KT4_Train_Main2.csv\", index = False)\n",
        "\n",
        "dfWithRequiredCols = val_data[['user_id', 'session_id', 'timestamp', 'item_id', 'action_type', 'source', 'correct']]\n",
        "dfWithRequiredCols.to_csv(\"C:\\\\Columbia\\\\RL\\\\EdNet_KT4_Val_Main2.csv\", index = False)\n",
        "\n",
        "dfWithRequiredCols = test_data[['user_id', 'session_id', 'timestamp', 'item_id', 'action_type', 'source', 'correct']]\n",
        "dfWithRequiredCols.to_csv(\"C:\\\\Columbia\\\\RL\\\\EdNet_KT4_Test_Main2.csv\", index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Few Hyperparams"
      ],
      "metadata": {
        "id": "moFD0CwSSX82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 1.0\n",
        "beta = 0.0\n",
        "action_labels = [\"recommend_question\", \"recommend_video\", \"recommend_explanation\"]\n",
        "action_dim = len(action_labels)\n",
        "\n",
        "max_time = 300000  # normalization factor"
      ],
      "metadata": {
        "id": "IFKYvu5uSW63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, get data in shape to process via Offline RL Algos"
      ],
      "metadata": {
        "id": "djI6JJrAR4Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = \"/content/drive/MyDrive/RL/EdNet_KT4_Train_Main2.csv\"\n",
        "val_file = \"/content/drive/MyDrive/RL/EdNet_KT4_Val_Main2.csv\"\n",
        "test_file = \"/content/drive/MyDrive/RL/EdNet_KT4_Test_Main2.csv\"\n",
        "\n",
        "train_df = pd.read_csv(train_file)\n",
        "val_df = pd.read_csv(val_file)\n",
        "test_df = pd.read_csv(test_file)"
      ],
      "metadata": {
        "id": "rJenG1A-R8cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define actions as high-level content recommendations:\n",
        "# 0: recommend a question\n",
        "# 1: recommend a video\n",
        "# 2: recommend explanation/content\n",
        "# You can decide the mapping based on action_type/source or other signals in your data.\n",
        "\n",
        "# Assume columns: user_id, session_id, timestamp, cursor_time, action_type, source, correct\n",
        "\n",
        "############################################\n",
        "# Step 2: Map Interactions to Actions\n",
        "############################################\n",
        "# For simplicity, let's define a function that maps the row to one of the three high-level actions.\n",
        "# This is a heuristic. In practice, youâ€™d have logic that determines which content type was recommended.\n",
        "\n",
        "def is_question(item_id):\n",
        "    return isinstance(item_id, str) and item_id.startswith('q')\n",
        "\n",
        "def is_explanation(item_id):\n",
        "    return isinstance(item_id, str) and item_id.startswith('e')\n",
        "\n",
        "def process_session(session_df):\n",
        "    session_df = session_df.to_dict('records')\n",
        "    events_list = []\n",
        "\n",
        "    # Track the current events:\n",
        "    # Textual explanation: enter (start), quit (end) or next question (if no quit)\n",
        "    textual_start = None   # (timestamp, item_id)\n",
        "    # Video explanation: play (start), pause (end) or next question (if no pause)\n",
        "    video_start = None     # (timestamp, item_id)\n",
        "    # Respond: keep track of the last respond before submit\n",
        "    last_respond = None    # (timestamp, action_info)\n",
        "\n",
        "    for i, ev in enumerate(session_df):\n",
        "        at = ev['action_type']\n",
        "        ts = ev['timestamp']\n",
        "        item = ev.get('item_id', None)\n",
        "        src = ev.get('source', None)\n",
        "        corr = ev.get('correct', None)\n",
        "\n",
        "        # Handle textual explanation events\n",
        "        if is_explanation(item):\n",
        "            if at == 'enter':\n",
        "                # Start textual explanation (if none ongoing)\n",
        "                textual_start = (ts, item)\n",
        "            elif at == 'quit' and textual_start is not None:\n",
        "                # End textual explanation\n",
        "                start_ts, start_item = textual_start\n",
        "                engagement_time = ts - start_ts\n",
        "                events_list.append({\n",
        "                    'user_id': ev['user_id'],\n",
        "                    'session_id': ev['session_id'],\n",
        "                    'event_type': 'textual_explanation',\n",
        "                    'engagement_time': engagement_time,\n",
        "                    'correct': None,\n",
        "                    'source': None\n",
        "                })\n",
        "                textual_start = None\n",
        "\n",
        "        # Handle video explanation events\n",
        "        if at in ['play_audio','play_video'] and video_start is None:\n",
        "            video_start = (ts, item)\n",
        "        elif at in ['pause_audio','pause_video'] and video_start is not None:\n",
        "            # End video explanation\n",
        "            start_ts, start_item = video_start\n",
        "            engagement_time = ts - start_ts\n",
        "            events_list.append({\n",
        "                'user_id': ev['user_id'],\n",
        "                'session_id': ev['session_id'],\n",
        "                'event_type': 'video_explanation',\n",
        "                'engagement_time': engagement_time,\n",
        "                'correct': None,\n",
        "                'source': None\n",
        "            })\n",
        "            video_start = None\n",
        "\n",
        "        # Handle respond event (track only last respond)\n",
        "        if at == 'respond' and is_question(item):\n",
        "            last_respond = (ts, ev)  # store the whole event if needed\n",
        "\n",
        "        # Handle question event\n",
        "        if at == 'submit':\n",
        "            # Close any ongoing textual or video explanation here if not ended\n",
        "            question_ts = ts\n",
        "\n",
        "            # If textual explanation was ongoing with no quit, end now\n",
        "            if textual_start is not None:\n",
        "                start_ts, start_item = textual_start\n",
        "                engagement_time = question_ts - start_ts\n",
        "                events_list.append({\n",
        "                    'user_id': ev['user_id'],\n",
        "                    'session_id': ev['session_id'],\n",
        "                    'event_type': 'textual_explanation',\n",
        "                    'engagement_time': engagement_time,\n",
        "                    'correct': None,\n",
        "                    'source': None\n",
        "                })\n",
        "                textual_start = None\n",
        "\n",
        "            # If video explanation was ongoing with no pause, end now\n",
        "            if video_start is not None:\n",
        "                start_ts, start_item = video_start\n",
        "                engagement_time = question_ts - start_ts\n",
        "                events_list.append({\n",
        "                    'user_id': ev['user_id'],\n",
        "                    'session_id': ev['session_id'],\n",
        "                    'event_type': 'video_explanation',\n",
        "                    'engagement_time': engagement_time,\n",
        "                    'correct': None,\n",
        "                    'source': None\n",
        "                })\n",
        "                video_start = None\n",
        "\n",
        "            # For the question event:\n",
        "            # engagement_time = 0\n",
        "            # correct and source from current event\n",
        "            # Only last respond before submit is considered as final chosen answer,\n",
        "            # but correctness presumably comes from the submit line itself.\n",
        "            # If you need to use last_respond info (e.g. user_answer), you can do so here.\n",
        "            if last_respond is not None:\n",
        "                corr = last_respond[1].get('correct', None)\n",
        "                src = last_respond[1].get('source', None)\n",
        "                events_list.append({\n",
        "                    'user_id': ev['user_id'],\n",
        "                    'session_id': ev['session_id'],\n",
        "                    'event_type': 'question',\n",
        "                    'engagement_time': 0,\n",
        "                    'correct': corr,\n",
        "                    'source': src\n",
        "                })\n",
        "\n",
        "            # Reset last_respond after the question\n",
        "            last_respond = None\n",
        "\n",
        "    # If a session ends without submit, any ongoing textual/video block is discarded\n",
        "    # since we only consider explanation events tied to transitions ending in a question.\n",
        "\n",
        "    return events_list"
      ],
      "metadata": {
        "id": "-31oeZseSejI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = train_df.groupby(['user_id','session_id'], as_index=False)\n",
        "all_events = []\n",
        "count = 0\n",
        "for (uid,sid), grp in tqdm(grouped, desc=\"Processing sessions\"):\n",
        "    grp = grp.sort_values('timestamp')\n",
        "    session_events = process_session(grp)\n",
        "    all_events.extend(session_events)\n",
        "    count += 1\n",
        "    if count > 100000:\n",
        "        break\n",
        "\n",
        "final_train_df = pd.DataFrame(all_events)\n",
        "\n",
        "grouped = val_df.groupby(['user_id','session_id'], as_index=False)\n",
        "all_events = []\n",
        "for (uid,sid), grp in tqdm(grouped, desc=\"Processing sessions\"):\n",
        "    grp = grp.sort_values('timestamp')\n",
        "    session_events = process_session(grp)\n",
        "    all_events.extend(session_events)\n",
        "\n",
        "final_val_df = pd.DataFrame(all_events)\n",
        "\n",
        "grouped = test_df.groupby(['user_id','session_id'], as_index=False)\n",
        "all_events = []\n",
        "for (uid,sid), grp in tqdm(grouped, desc=\"Processing sessions\"):\n",
        "    grp = grp.sort_values('timestamp')\n",
        "    session_events = process_session(grp)\n",
        "    all_events.extend(session_events)\n",
        "\n",
        "final_test_df = pd.DataFrame(all_events)"
      ],
      "metadata": {
        "id": "Jd3A1wwJShKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_types = [\"question\", \"textual_explanation\", \"video_explanation\"]\n",
        "event_type_to_idx = {e: i for i, e in enumerate(event_types)}\n",
        "\n",
        "sources = final_train_df['source'].dropna().unique().tolist() if 'source' in final_train_df.columns else []\n",
        "source_to_idx = {s: i for i, s in enumerate(sources)}\n",
        "\n",
        "state_length = 5\n",
        "max_engagement = 30000.0  # Arbitrary normalization factor for engagement time\n",
        "\n",
        "def one_hot_encode(idx, size):\n",
        "    v = np.zeros(size)\n",
        "    v[idx] = 1.0\n",
        "    return v\n",
        "\n",
        "def featurize_event(row):\n",
        "    # One-hot event_type\n",
        "    et_vec = one_hot_encode(event_type_to_idx[row['event_type']], len(event_types))\n",
        "\n",
        "    # Correctness\n",
        "    # If NaN or None for explanation, treat as 0\n",
        "    corr = row['correct']\n",
        "    corr_val = 0.0 if pd.isnull(corr) else float(corr)\n",
        "\n",
        "    # Engagement time (not directly used for current event as a feature,\n",
        "    # but we can include it. For question, it's always 0.)\n",
        "    eng_time = row['engagement_time']\n",
        "    eng_time_val = 0.0 if pd.isnull(eng_time) else float(eng_time) / max_engagement\n",
        "    eng_time_val = min(eng_time_val, 1.0)  # clip\n",
        "\n",
        "    # Source (only meaningful if question)\n",
        "    src = row['source']\n",
        "    if src in source_to_idx:\n",
        "        src_vec = one_hot_encode(source_to_idx[src], len(sources))\n",
        "    else:\n",
        "        # If not applicable or unknown, zero vector\n",
        "        src_vec = np.zeros(len(sources))\n",
        "\n",
        "    # Final feature: [et_vec, corr_val, eng_time_val, src_vec]\n",
        "    feat = np.concatenate([et_vec, [corr_val, eng_time_val], src_vec])\n",
        "    return feat\n",
        "\n",
        "def featurize_state(events, state_length=5):\n",
        "    # events: list of rows (dict)\n",
        "    # If fewer than state_length, pad with zero features\n",
        "\n",
        "    feats = [featurize_event(e) for e in events]\n",
        "\n",
        "    # Determine the dimension of a single event's feature vector\n",
        "    # If we have no events, create a dummy event to determine dimension\n",
        "    if len(feats) == 0:\n",
        "        dummy_event = {\"event_type\": \"question\", \"correct\": 0, \"engagement_time\": 0, \"source\": None}\n",
        "        dummy_feat = featurize_event(dummy_event)\n",
        "        dim = len(dummy_feat)\n",
        "    else:\n",
        "        dim = len(feats[0])\n",
        "\n",
        "    # If fewer than state_length, pad with zero vectors at the front\n",
        "    if len(feats) < state_length:\n",
        "        padding_needed = state_length - len(feats)\n",
        "        padding = [np.zeros(dim) for _ in range(padding_needed)]\n",
        "        feats = padding + feats\n",
        "    else:\n",
        "        # If more events than state_length, take the last state_length\n",
        "        feats = feats[-state_length:]\n",
        "\n",
        "    # Concatenate into a single state vector\n",
        "    state_vec = np.concatenate(feats)\n",
        "    return state_vec"
      ],
      "metadata": {
        "id": "0EWAsHY5Sodb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "event_types = [\"question\", \"textual_explanation\", \"video_explanation\"]\n",
        "event_type_to_idx = {e: i for i, e in enumerate(event_types)}\n",
        "\n",
        "# Compute mean and std for textual and video engagement times from the training set\n",
        "def compute_engagement_stats(df):\n",
        "    textual_times = df.loc[df['event_type'] == 'textual_explanation', 'engagement_time'].dropna()\n",
        "    video_times = df.loc[df['event_type'] == 'video_explanation', 'engagement_time'].dropna()\n",
        "\n",
        "    textual_mean = textual_times.mean() if len(textual_times) > 0 else 0.0\n",
        "    textual_std = textual_times.std() if len(textual_times) > 0 else 1.0\n",
        "    if textual_std == 0:  # Avoid division by zero\n",
        "        textual_std = 1.0\n",
        "\n",
        "    video_mean = video_times.mean() if len(video_times) > 0 else 0.0\n",
        "    video_std = video_times.std() if len(video_times) > 0 else 1.0\n",
        "    if video_std == 0:\n",
        "        video_std = 1.0\n",
        "\n",
        "    return textual_mean, textual_std, video_mean, video_std\n",
        "\n",
        "# Compute reward given a single event row\n",
        "def compute_reward(row, textual_mean, textual_std, video_mean, video_std, alpha = 0.5, beta = 0.5):\n",
        "    et = row['event_type']\n",
        "    if et == 'question':\n",
        "        # reward = correctness (0 or 1)\n",
        "        corr = row.get('correct', 0)\n",
        "        return alpha * (1.0 if corr == 1 else 0.0)\n",
        "    elif et == 'textual_explanation':\n",
        "        # Normalize engagement\n",
        "        eng = row.get('engagement_time', 0.0)\n",
        "        normalized = (eng - textual_mean) / textual_std\n",
        "        # Clip to [0, 1]\n",
        "        return beta * (min(max(normalized, 0.0), 1.0))\n",
        "    elif et == 'video_explanation':\n",
        "        eng = row.get('engagement_time', 0.0)\n",
        "        normalized = (eng - video_mean) / video_std\n",
        "        return beta * (min(max(normalized, 0.0), 1.0))\n",
        "    else:\n",
        "        # Should not happen\n",
        "        return 0.0\n",
        "\n",
        "def build_dataset(df, textual_mean, textual_std, video_mean, video_std, state_length=5, alpha = 0.5, beta = 0.5):\n",
        "    # We assume df has columns:\n",
        "    # user_id, session_id, event_type, engagement_time, correct, source\n",
        "    # Sort by user, session, and some time indicator if not already sorted\n",
        "    # (assuming already sorted)\n",
        "\n",
        "    transitions = []\n",
        "\n",
        "    grouped = df.groupby(['user_id','session_id'], as_index=False)\n",
        "    for (uid,sid), grp in tqdm(grouped, desc=\"Building dataset\"):\n",
        "        grp = grp.to_dict('records')\n",
        "\n",
        "        # We create transitions from consecutive events\n",
        "        # For each event at index i, state = last state_length events before i\n",
        "        # action = event_type of current event\n",
        "        # reward = computed from current event\n",
        "        # next_state = last state_length events before i+1\n",
        "        # done = True if i+1 is out of range (end of session)\n",
        "        for i in range(len(grp)-1):\n",
        "            current_event = grp[i]\n",
        "            next_event = grp[i+1]\n",
        "\n",
        "            # state\n",
        "            prev_events = grp[max(0, i - state_length):i]\n",
        "            s = featurize_state(prev_events, state_length=state_length)\n",
        "\n",
        "            # action\n",
        "            a = event_type_to_idx[current_event['event_type']]\n",
        "\n",
        "            # reward\n",
        "            r = compute_reward(current_event, textual_mean, textual_std, video_mean, video_std, alpha = alpha, beta = beta)\n",
        "\n",
        "            # next_state\n",
        "            next_prev_events = grp[max(0, (i+1) - state_length):(i+1)]\n",
        "            s_next = featurize_state(next_prev_events, state_length=state_length)\n",
        "\n",
        "            done = (i == len(grp)-2)  # last transition in this session\n",
        "\n",
        "            transitions.append((s, a, r, s_next, done))\n",
        "\n",
        "    return transitions\n",
        "\n",
        "textual_mean, textual_std, video_mean, video_std = compute_engagement_stats(final_train_df)"
      ],
      "metadata": {
        "id": "A96lQrDnSxjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the dataset"
      ],
      "metadata": {
        "id": "mQV5Uo3ATSqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = build_dataset(final_train_df, textual_mean, textual_std, video_mean, video_std, state_length=5, alpha = alpha, beta = beta)\n",
        "val_data = build_dataset(final_val_df, textual_mean, textual_std, video_mean, video_std, state_length=5, alpha = alpha, beta = beta)\n",
        "test_data = build_dataset(final_test_df, textual_mean, textual_std, video_mean, video_std, state_length=5, alpha = alpha, beta = beta)"
      ],
      "metadata": {
        "id": "8EhF8v88TSCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_mdpdataset(transitions):\n",
        "    s_arr = np.array([t[0] for t in transitions], dtype=np.float32)\n",
        "    a_arr = np.array([t[1] for t in transitions], dtype=np.int64)\n",
        "    r_arr = np.array([t[2] for t in transitions], dtype=np.float32)\n",
        "    d_arr = np.array([t[4] for t in transitions], dtype=np.bool_)\n",
        "    return MDPDataset(observations=s_arr, actions=a_arr, rewards=r_arr, terminals=d_arr)"
      ],
      "metadata": {
        "id": "b-SM45V6TVve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = to_mdpdataset(train_data)\n",
        "val_dataset = to_mdpdataset(val_data)\n",
        "test_dataset = to_mdpdataset(test_data)"
      ],
      "metadata": {
        "id": "gZrVjdE5TXOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to evaluate and visualize sessions"
      ],
      "metadata": {
        "id": "5dcTqXYhTgLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "event_types = [\"question\", \"textual_explanation\", \"video_explanation\"]\n",
        "action_labels = event_types\n",
        "\n",
        "def evaluate_bc_policy(bc_policy, dataset, name=\"BC Policy\", trajectory_length=50):\n",
        "    # Evaluates BC by measuring action match accuracy.\n",
        "    # BC does not produce Q-values.\n",
        "    traj = dataset.sample_trajectory(trajectory_length)\n",
        "    observations = traj.observations\n",
        "    actions = traj.actions\n",
        "\n",
        "    correct_predictions = 0\n",
        "    for o, a in zip(observations, actions):\n",
        "        o_np = o[np.newaxis, :]\n",
        "        predicted_action = bc_policy.predict(o_np)[0]  # returns predicted action\n",
        "        if predicted_action == a:\n",
        "            correct_predictions += 1\n",
        "    accuracy = correct_predictions / len(observations) if len(observations) > 0 else 0\n",
        "    print(f\"{name} Action Match Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "\n",
        "def visualize_bc_policy(bc_policy, dataset, action_labels, num_states=5, trajectory_length=5):\n",
        "    # Visualize BC by showing what action it chooses vs the true action.\n",
        "    # BC does not have Q-values, so we just show chosen vs actual action.\n",
        "    for _ in range(num_states):\n",
        "        traj = dataset.sample_trajectory(trajectory_length)\n",
        "        observations = traj.observations\n",
        "        actions = traj.actions\n",
        "\n",
        "        if len(observations) == 0:\n",
        "            print(\"Empty trajectory, skipping.\")\n",
        "            continue\n",
        "\n",
        "        idx = np.random.randint(len(observations))\n",
        "        obs = observations[idx][np.newaxis, :]\n",
        "        predicted_action = bc_policy.predict(obs)[0]\n",
        "        true_action = actions[idx][0]\n",
        "        # print(true_action, predicted_action)\n",
        "\n",
        "        print(f\"True Next Action: {action_labels[true_action]}, Predicted Next Action: {action_labels[predicted_action]}\")\n",
        "\n",
        "        # Create a bar plot with 0s for non-chosen actions, 1 for chosen action\n",
        "        action_values = np.zeros(len(action_labels))\n",
        "        action_values[predicted_action] = 1.0\n",
        "\n",
        "        plt.figure(figsize=(6,4))\n",
        "        plt.bar(range(len(action_labels)), action_values, tick_label=action_labels)\n",
        "        plt.title(\"Chosen Action for a Sampled State\")\n",
        "        plt.xlabel(\"Action\")\n",
        "        plt.ylabel(\"Selection Indicator\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def evaluate_q_policy(policy, dataset, name=\"Policy\", trajectory_length=50, numSamplings = 100):\n",
        "    # Evaluates Q-based policies (CQL, BCQ, IQL) by computing average Q-value on a sampled trajectory\n",
        "    q_vals = []\n",
        "    for _ in range(numSamplings):\n",
        "        traj = dataset.sample_trajectory(trajectory_length)\n",
        "        observations = traj.observations\n",
        "        actions = traj.actions\n",
        "        if len(observations) == 0:\n",
        "            print(f\"{name} Average Q-value: N/A (no data)\")\n",
        "            return\n",
        "\n",
        "        for o, a in zip(observations, actions):\n",
        "            o_np = o[np.newaxis, :]\n",
        "            q = policy.predict_value(o_np, np.array([a]))\n",
        "            q_vals.append(q[0])\n",
        "    print(f\"{name} Average Q-value: {np.mean(q_vals):.4f}\")\n",
        "\n",
        "\n",
        "def decode_event_vector(event_vec):\n",
        "    # This is pseudo-code and must be adapted to your feature indexing\n",
        "    # Assuming featurize_event creates a feature vector:\n",
        "    # feat = np.concatenate([et_vec, [corr_val, eng_time_val], src_vec])\n",
        "    # [one-hot event_type (len(event_types)), correctness(1), eng_time_norm(1), source_one_hot(len(sources))]\n",
        "    et_size = len(event_types)\n",
        "    src_size = len(sources)\n",
        "    # Layout: [et_vec, corr, eng_time_norm, src_vec]\n",
        "    et_vec = event_vec[:et_size]\n",
        "    corr_val = event_vec[et_size]\n",
        "    eng_time_norm = event_vec[et_size+1]\n",
        "    src_vec = event_vec[et_size+2:et_size+2+src_size]\n",
        "\n",
        "    et_idx = np.argmax(et_vec) if np.max(et_vec) > 0 else None\n",
        "    et_str = event_types[et_idx] if et_idx is not None else \"PAD\"\n",
        "\n",
        "    correct = int(round(corr_val))\n",
        "\n",
        "    src_str = \"None\"\n",
        "    if src_size > 0 and np.max(src_vec) > 0:\n",
        "        src_idx = np.argmax(src_vec)\n",
        "        src_str = sources[src_idx]\n",
        "\n",
        "    # Return a readable dictionary\n",
        "    return {\n",
        "        \"event_type\": et_str,\n",
        "        \"correct\": correct,\n",
        "        \"engagement_norm\": eng_time_norm,\n",
        "        \"source\": src_str\n",
        "    }\n",
        "\n",
        "def decode_state(state_vec, state_length=5):\n",
        "    # Based on featurize_state logic\n",
        "    et_size = len(event_types)\n",
        "    src_size = len(sources)\n",
        "    per_event_dim = et_size + 1 + 1 + src_size  # event_type + correct + eng + sources\n",
        "    assert len(state_vec) == state_length * per_event_dim, \"State vector length mismatch.\"\n",
        "\n",
        "    events = []\n",
        "    for i in range(state_length):\n",
        "        start = i * per_event_dim\n",
        "        end = start + per_event_dim\n",
        "        event_vec = state_vec[start:end]\n",
        "        ev = decode_event_vector(event_vec)\n",
        "        events.append(ev)\n",
        "    return events\n",
        "\n",
        "def visualize_q_policy(policy, dataset, action_labels, num_states=5, trajectory_length=5):\n",
        "    for _ in range(num_states):\n",
        "        traj = dataset.sample_trajectory(trajectory_length)\n",
        "        observations = traj.observations\n",
        "        actions = traj.actions\n",
        "        rewards = traj.rewards  # if needed\n",
        "        terminals = traj.terminals\n",
        "\n",
        "        if len(observations) == 0:\n",
        "            print(\"Empty trajectory, skipping.\")\n",
        "            continue\n",
        "\n",
        "        idx = min(4, len(observations)-1) # Hardcode for now\n",
        "        obs = observations[idx][np.newaxis, :]\n",
        "        q_vals = policy.predict_value(obs, np.arange(len(action_labels)))\n",
        "\n",
        "        true_action = actions[idx][0]\n",
        "        predicted_action = np.argmax(q_vals)\n",
        "\n",
        "        # Decode the current state (last 5 events)\n",
        "        # The current state = observations[idx]\n",
        "        # It's already featurized state. We can decode it:\n",
        "        current_state = observations[idx]  # shape: [state_dim]\n",
        "        decoded_events = decode_state(current_state, state_length=5)\n",
        "\n",
        "        print(\"---- PREDICTION POINT ----\")\n",
        "        print(\"State (last 5 events):\")\n",
        "        for i, ev in enumerate(decoded_events, start=1):\n",
        "            print(f\"  Step {i}: Event_Type={ev['event_type']}, Correct={ev['correct']}, \"\n",
        "                  f\"Engagement_Norm={ev['engagement_norm']:.2f}, Source={ev['source']}\")\n",
        "\n",
        "        true_action_str = action_labels[true_action] if true_action < len(action_labels) else f\"Action_{true_action}\"\n",
        "        predicted_action_str = action_labels[predicted_action] if predicted_action < len(action_labels) else f\"Action_{predicted_action}\"\n",
        "\n",
        "        print(f\"True Next Action: {true_action_str}, Predicted Next Action: {predicted_action_str}\")\n",
        "\n",
        "        # Print the entire session (trajectory) up to this point if desired.\n",
        "        # We have all observations up to idx. Let's decode each state at each timestep (optional).\n",
        "        print(\"\\nEntire trajectory up to this point:\")\n",
        "        for t in range(idx+1):\n",
        "            state_at_t = observations[t]\n",
        "            evs = decode_state(state_at_t, state_length=5)\n",
        "            chosen_action = actions[t][0]\n",
        "            chosen_action_str = action_labels[chosen_action] if chosen_action < len(action_labels) else f\"Action_{chosen_action}\"\n",
        "            print(f\"Time {t}:\")\n",
        "            for e_id, ev_info in enumerate(evs, start=1):\n",
        "                print(f\"  Step {e_id}: {ev_info}\")\n",
        "            print(f\"  Executed Action: {chosen_action_str}\\n\")\n",
        "\n",
        "        # Plot Q-values\n",
        "        plt.figure(figsize=(6,4))\n",
        "        plt.bar(range(len(action_labels)), q_vals, tick_label=action_labels)\n",
        "        plt.title(\"Q-values for the sampled state\")\n",
        "        plt.xlabel(\"Action\")\n",
        "        plt.ylabel(\"Predicted Q-value\")\n",
        "        plt.show()\n",
        "        print(\"=\"*50 + \"\\n\")"
      ],
      "metadata": {
        "id": "UIeUYrNATdtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training code"
      ],
      "metadata": {
        "id": "HeweXxycTUrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# Step 5: Train Offline RL Algorithms\n",
        "############################################\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "# 3. Set enable_ddp (usually False for single-process training)\n",
        "enable_ddp = False\n",
        "bc = d3rlpy.algos.DiscreteBCConfig(batch_size = 1024, learning_rate = 0.01).create(device=True)\n",
        "print(\"Training BC...\")\n",
        "bc.fit(train_dataset, n_steps = 50000, logging_steps = 1000)  # Increase epochs as needed"
      ],
      "metadata": {
        "id": "kX3tQXODTbZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_bc_policy(bc, test_dataset, \"BC\")\n",
        "print(\"Visualizing BC policy:\")\n",
        "visualize_bc_policy(bc, test_dataset, action_labels)"
      ],
      "metadata": {
        "id": "cldVKKjQTl-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cql = d3rlpy.algos.DiscreteCQLConfig(batch_size = 1024).create(device=True)\n",
        "print(\"Training CQL...\")\n",
        "cql.fit(train_dataset, n_steps = 50000, logging_steps = 1000)"
      ],
      "metadata": {
        "id": "GqX5Wkz2TnzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_q_policy(cql, test_dataset, \"CQL\")\n",
        "print(\"Visualizing CQL policy:\")\n",
        "visualize_q_policy(cql, test_dataset, action_labels=action_labels)"
      ],
      "metadata": {
        "id": "wF2aBrrLTqHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bcq = d3rlpy.algos.DiscreteBCQConfig(batch_size = 1024).create(device=True)\n",
        "print(\"Training BCQ...\")\n",
        "bcq.fit(train_dataset, n_steps = 50000, logging_steps = 1000)\n"
      ],
      "metadata": {
        "id": "u9FZsuaHTsbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_q_policy(bcq, test_dataset, \"BCQ\")\n",
        "print(\"Visualizing BCQ policy:\")\n",
        "visualize_q_policy(bcq, test_dataset, action_labels=action_labels)"
      ],
      "metadata": {
        "id": "-UN-YOxgTu2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sac = d3rlpy.algos.DiscreteSACConfig(batch_size = 1024).create(device=True)\n",
        "print(\"Training SAC...\")\n",
        "sac.fit(train_dataset, n_steps = 50000, logging_steps = 1000)"
      ],
      "metadata": {
        "id": "v5XaYJ09TwPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_q_policy(sac, test_dataset, \"SAC\")\n",
        "print(\"Visualizing SAC policy:\")\n",
        "visualize_q_policy(sac, test_dataset, action_labels=action_labels)"
      ],
      "metadata": {
        "id": "vmPox0GFT0cg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}